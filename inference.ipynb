{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force complete reimport of model module with all dependencies\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove all model-related modules from cache\n",
    "modules_to_remove = [key for key in sys.modules.keys() if 'model' in key.lower()]\n",
    "for module_name in modules_to_remove:\n",
    "    del sys.modules[module_name]\n",
    "\n",
    "# Reimport fresh\n",
    "import model\n",
    "importlib.reload(model)\n",
    "print(\"\u2713 Model module reloaded successfully\")\n",
    "print(f\"\u2713 NoiseInjectionLayer available: {hasattr(model, 'NoiseInjectionLayer')}\")\n",
    "print(f\"\u2713 PricePredictor available: {hasattr(model, 'PricePredictor')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, losses, initializers, regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, f1_score, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, FuncFormatter\n",
    "\n",
    "# Reload project model module to pick up latest edits when iterating in the notebook\n",
    "import model\n",
    "importlib.reload(model)\n",
    "from model import *\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Output, VBox, HBox, Label, FloatProgress\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Global variables for persistence\n",
    "estimated_time_per_batch = None\n",
    "total_time = None\n",
    "pause_training = False\n",
    "stop_training = False\n",
    "\n",
    "class InteractivePlotCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, config, loss_output, metrics_output, progress_widget, total_epochs, batch_output=None, batch_metrics_output=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.loss_output = loss_output\n",
    "        self.metrics_output = metrics_output\n",
    "        self.progress_widget = progress_widget\n",
    "        self.total_epochs = total_epochs\n",
    "        self.history = {}\n",
    "        self.epoch_count = 0\n",
    "\n",
    "        # Batch-level widgets and history (text output no longer used)\n",
    "        self.batch_metrics_output = batch_metrics_output or Output()\n",
    "        self.batch_history = {}  # stores lists per metric for current epoch\n",
    "        self.total_batches = None\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"Flush batch-level displays and reset batch history at the start of each epoch.\"\"\"\n",
    "        # Reset per-epoch batch history\n",
    "        self.batch_history.clear()\n",
    "        self.batch_count = 0\n",
    "        # total batches may be available in params\n",
    "        self.total_batches = self.params.get('steps') if self.params is not None else None\n",
    "\n",
    "        # Clear batch plot output\n",
    "        with self.batch_metrics_output:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        \"\"\"Capture per-batch logs and update batch plot only (no text logging).\"\"\"\n",
    "        logs = logs or {}\n",
    "        # Keras batch index starts at 0; store 1-based\n",
    "        batch_idx = (batch or 0) + 1\n",
    "        self.batch_history.setdefault('batch', []).append(batch_idx)\n",
    "        for key, value in logs.items():\n",
    "            try:\n",
    "                self.batch_history.setdefault(key, []).append(float(value))\n",
    "            except Exception:\n",
    "                # skip non-numeric values\n",
    "                pass\n",
    "        self.batch_count = len(self.batch_history['batch'])\n",
    "\n",
    "        # Update plot only\n",
    "        try:\n",
    "            self.update_batch_plot()\n",
    "        except Exception:\n",
    "            # Avoid breaking training if plotting fails\n",
    "            pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global pause_training, stop_training\n",
    "        if stop_training:\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "        if pause_training:\n",
    "            while pause_training and not stop_training:\n",
    "                time.sleep(0.1)\n",
    "            if stop_training:\n",
    "                self.model.stop_training = True\n",
    "                return\n",
    "\n",
    "        logs = logs or {}\n",
    "        self.epoch_count = epoch + 1\n",
    "\n",
    "        # Collect all losses and metrics for epoch-level persistent history\n",
    "        loss_types = ['loss', 'val_loss', 'point_loss', 'val_point_loss', 'trend_loss', 'val_trend_loss',\n",
    "                      'local_trend_loss', 'val_local_trend_loss', 'global_trend_loss', 'val_global_trend_loss',\n",
    "                      'extended_trend_loss', 'val_extended_trend_loss', 'dir_loss', 'val_dir_loss',\n",
    "                      'reg_loss', 'val_reg_loss', 'vol_loss', 'val_vol_loss', 'var_nll', 'val_var_nll']\n",
    "        for m in loss_types:\n",
    "            if m in logs:\n",
    "                self.history.setdefault(m, []).append(float(logs[m]))\n",
    "\n",
    "        metric_types = ['val_f1', 'val_dir_acc', 'val_precision', 'val_recall']\n",
    "        for m in metric_types:\n",
    "            if m in logs:\n",
    "                self.history.setdefault(m, []).append(float(logs[m]))\n",
    "\n",
    "        # Update epoch-level plots\n",
    "        self.update_loss_plot()\n",
    "        self.update_metrics_plot()\n",
    "\n",
    "        # Update progress bar\n",
    "        self.progress_widget.value = self.epoch_count\n",
    "        self.progress_widget.description = f\"Epoch {self.epoch_count}/{self.total_epochs}\"\n",
    "\n",
    "    def update_loss_plot(self):\n",
    "        \"\"\"Update persistent loss plot with all loss types grouped\"\"\"\n",
    "        epochs = list(range(1, self.epoch_count + 1))\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Training losses\n",
    "        if 'loss' in self.history and self.history['loss']:\n",
    "            fig.add_trace(go.Scatter(x=epochs, y=self.history['loss'], mode='lines', \n",
    "                                    name='Total Loss', line=dict(width=2, color='blue')))\n",
    "\n",
    "        # Validation losses\n",
    "        if 'val_loss' in self.history and self.history['val_loss']:\n",
    "            fig.add_trace(go.Scatter(x=epochs, y=self.history['val_loss'], mode='lines', \n",
    "                                    name='Val Loss', line=dict(width=2, color='red', dash='dash')))\n",
    "\n",
    "        # Point losses\n",
    "        for loss_name in ['point_loss', 'val_point_loss']:\n",
    "            if loss_name in self.history and self.history[loss_name]:\n",
    "                fig.add_trace(go.Scatter(x=epochs, y=self.history[loss_name], mode='lines', \n",
    "                                        name=loss_name, line=dict(width=1.5)))\n",
    "\n",
    "        # Trend losses\n",
    "        for loss_name in ['trend_loss', 'val_trend_loss', 'local_trend_loss', 'val_local_trend_loss',\n",
    "                         'global_trend_loss', 'val_global_trend_loss', 'extended_trend_loss', 'val_extended_trend_loss',\n",
    "                         'dir_loss', 'val_dir_loss', 'reg_loss', 'val_reg_loss', 'vol_loss', 'val_vol_loss', 'var_nll', 'val_var_nll']:\n",
    "            if loss_name in self.history and self.history[loss_name]:\n",
    "                fig.add_trace(go.Scatter(x=epochs, y=self.history[loss_name], mode='lines', \n",
    "                                        name=loss_name, line=dict(width=1), opacity=0.7))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title='Training Progress: All Losses',\n",
    "            xaxis_title='Epoch',\n",
    "            yaxis_title='Loss Value',\n",
    "            hovermode='x unified',\n",
    "            height=500,\n",
    "            width=1200,\n",
    "            template='plotly_dark',\n",
    "            legend=dict(x=1.01, y=1, xanchor='left', yanchor='top'),\n",
    "            showlegend=True,\n",
    "        )\n",
    "\n",
    "        with self.loss_output:\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    def update_metrics_plot(self):\n",
    "        \"\"\"Update persistent metrics plot with all metric types\"\"\"\n",
    "        epochs = list(range(1, self.epoch_count + 1))\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Directional metrics\n",
    "        for metric_name in ['val_f1', 'val_dir_acc', 'val_precision', 'val_recall']:\n",
    "            if metric_name in self.history and self.history[metric_name]:\n",
    "                fig.add_trace(go.Scatter(x=epochs, y=self.history[metric_name], mode='lines+markers', \n",
    "                                        name=metric_name, line=dict(width=2)))\n",
    "\n",
    "        # Add 50% threshold baseline\n",
    "        if self.epoch_count > 0:\n",
    "            fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "        fig.update_layout(\n",
    "            title='Training Progress: Validation Metrics',\n",
    "            xaxis_title='Epoch',\n",
    "            yaxis_title='Metric Value',\n",
    "            yaxis=dict(range=[0, 1]),\n",
    "            hovermode='x unified',\n",
    "            height=400,\n",
    "            width=1200,\n",
    "            template='plotly_dark',\n",
    "            legend=dict(x=1.01, y=1, xanchor='left', yanchor='top'),\n",
    "            showlegend=True,\n",
    "        )\n",
    "\n",
    "        with self.metrics_output:\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "    def update_batch_plot(self):\n",
    "        \"\"\"Update a per-epoch batch-level plot inside batch_metrics_output.\"\"\"\n",
    "        batches = self.batch_history.get('batch', [])\n",
    "        if not batches:\n",
    "            return\n",
    "\n",
    "        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.08,\n",
    "                            subplot_titles=(\"Batch Loss (per-batch)\", \"Batch Metrics (per-batch)\"))\n",
    "\n",
    "        # Loss lines\n",
    "        loss_vals = self.batch_history.get('loss', [])\n",
    "        if loss_vals:\n",
    "            fig.add_trace(go.Scatter(x=batches, y=loss_vals, mode='lines+markers', name='batch_loss', line=dict(color='blue')), row=1, col=1)\n",
    "        val_loss_vals = self.batch_history.get('val_loss', [])\n",
    "        if val_loss_vals:\n",
    "            fig.add_trace(go.Scatter(x=batches, y=val_loss_vals, mode='lines+markers', name='batch_val_loss', line=dict(color='red', dash='dash')), row=1, col=1)\n",
    "\n",
    "        # Metric lines: dir_acc and f1 (plus optional validation counterparts if present)\n",
    "        dir_vals = self.batch_history.get('dir_acc', [])\n",
    "        if dir_vals:\n",
    "            fig.add_trace(go.Scatter(x=batches, y=dir_vals, mode='lines+markers', name='dir_acc', line=dict(color='royalblue')), row=2, col=1)\n",
    "        val_dir_vals = self.batch_history.get('val_dir_acc', [])\n",
    "        if val_dir_vals:\n",
    "            fig.add_trace(go.Scatter(x=batches, y=val_dir_vals, mode='lines+markers', name='val_dir_acc', line=dict(color='deepskyblue', dash='dash')), row=2, col=1)\n",
    "\n",
    "        f1_vals = self.batch_history.get('f1', [])\n",
    "        if f1_vals:\n",
    "            fig.add_trace(go.Scatter(x=batches, y=f1_vals, mode='lines+markers', name='f1', line=dict(color='orange')), row=2, col=1)\n",
    "        val_f1_vals = self.batch_history.get('val_f1', [])\n",
    "        if val_f1_vals:\n",
    "            fig.add_trace(go.Scatter(x=batches, y=val_f1_vals, mode='lines+markers', name='val_f1', line=dict(color='darkorange', dash='dash')), row=2, col=1)\n",
    "\n",
    "        # Add baseline 50% line on metric subplot\n",
    "        fig.update_yaxes(range=[0, 1], row=2, col=1)\n",
    "        fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"gray\", row=2, col=1)\n",
    "\n",
    "        fig.update_layout(\n",
    "            height=500,\n",
    "            width=1200,\n",
    "            template='plotly_dark',\n",
    "            hovermode='x unified',\n",
    "            showlegend=True,\n",
    "        )\n",
    "\n",
    "        with self.batch_metrics_output:\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "\n",
    "\n",
    "def limit_dataset_size(df, close_values, max_samples, lookback):\n",
    "    required_rows = max_samples + lookback\n",
    "    if len(df) > required_rows:\n",
    "        df_limited = df.tail(required_rows).copy()\n",
    "        close_limited = close_values[-required_rows:]\n",
    "        print(f\"Limited dataset to {len(df_limited):,} rows (most recent)\")\n",
    "        return df_limited, close_limited\n",
    "    return df, close_values\n",
    "\n",
    "def estimate_training_time(config, close_values, train_samples):\n",
    "    batches_per_epoch = train_samples // config.BATCH_SIZE\n",
    "    try:\n",
    "        predictor = PricePredictor(config)\n",
    "        base_model = predictor.build_model()\n",
    "        test_model = CustomTrainModel(base_model=base_model, pred_scale=1.0, pred_mean=0.0, config=config,\n",
    "                                      inputs=base_model.inputs, outputs=base_model.outputs)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config.LR)\n",
    "\n",
    "        # Create sample batch\n",
    "        close_np = np.array(close_values)\n",
    "        start_indices = np.arange(0, min(config.BATCH_SIZE * config.WINDOW_STEP, len(close_np) - config.LOOKBACK - 1), config.WINDOW_STEP)\n",
    "        X_batch = np.array([close_np[start:start + config.LOOKBACK] for start in start_indices[:config.BATCH_SIZE]])\n",
    "        y_batch = np.array([close_np[start + config.LOOKBACK] for start in start_indices[:config.BATCH_SIZE]])[:, np.newaxis]\n",
    "        last_close_batch = np.array([close_np[start + config.LOOKBACK - 1] for start in start_indices[:config.BATCH_SIZE]])[:, np.newaxis]\n",
    "        extended_batch = np.array([[close_np[start + config.LOOKBACK + p] for p in config.EXTENDED_TREND_PERIODS] for start in start_indices[:config.BATCH_SIZE]])\n",
    "\n",
    "        test_X = tf.convert_to_tensor(X_batch)\n",
    "        test_y = tf.convert_to_tensor(y_batch)\n",
    "        test_last_close = tf.convert_to_tensor(last_close_batch)\n",
    "        test_extended = tf.convert_to_tensor(extended_batch)\n",
    "\n",
    "        start_time = time.time()\n",
    "        with tqdm(total=3, desc=\"Benchmarking\", leave=False) as pbar:\n",
    "            for _ in range(3):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions = test_model(test_X, training=True)\n",
    "                    loss_components = test_model.custom_loss(test_X, test_y, predictions, test_last_close, test_extended)\n",
    "                    total_loss = loss_components[0]\n",
    "                grads = tape.gradient(total_loss, test_model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, test_model.trainable_variables))\n",
    "                pbar.update(1)\n",
    "        elapsed = time.time() - start_time\n",
    "        global estimated_time_per_batch\n",
    "        estimated_time_per_batch = (elapsed / 3) * (config.BATCH_SIZE / len(X_batch))\n",
    "    except Exception as e:\n",
    "        print(f\"Benchmarking failed: {e}\")\n",
    "        estimated_time_per_batch = 0.15 if tf.config.list_physical_devices('GPU') else 2.0\n",
    "\n",
    "    time_per_epoch = batches_per_epoch * estimated_time_per_batch\n",
    "    global total_time\n",
    "    total_time = time_per_epoch * config.EPOCHS\n",
    "    return estimated_time_per_batch, total_time\n",
    "\n",
    "def run_evaluation(model, scaler, X_test_seq, y_test, y_pred, last_close_test):\n",
    "    \"\"\"Run evaluation and display results\"\"\"\n",
    "    # Interactive evaluation plots\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Actual vs Predicted (Last 200)', 'Error Distribution'))\n",
    "    fig.add_trace(go.Scatter(y=y_test[-200:], mode='lines', name='Actual'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=y_pred[-200:], mode='lines', name='Predicted'), row=1, col=1)\n",
    "    errors = y_test - y_pred\n",
    "    fig.add_trace(go.Histogram(x=errors, nbinsx=50, name='Errors'), row=1, col=2)\n",
    "    fig.update_layout(height=400, width=1200, template='plotly_dark')\n",
    "    display(fig)\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    pred_dir = (y_pred - last_close_test) > 0\n",
    "    true_dir = (y_test - last_close_test) > 0\n",
    "    dir_acc = np.mean(pred_dir == true_dir)\n",
    "\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    print(f\"   MSE: {mse:.4f}\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   R-squared: {r2:.4f}\")\n",
    "    print(f\"   MAPE: {mape:.4f}\")\n",
    "    print(f\"   Direction Accuracy: {dir_acc:.2%}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Main Pipeline\n",
    "# ============================================================================\n",
    "print(\"Training and Inference Cell\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Check weights\n",
    "weights_exist = os.path.exists(config.MODEL_PATH)\n",
    "force = False  # Set to True to force retraining\n",
    "\n",
    "if not weights_exist or force:\n",
    "    print(\"Running Training Pipeline\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Setup GPU\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"GPU: {len(gpus)} detected\")\n",
    "        for gpu in gpus:\n",
    "            print(f\"   {gpu.name}\")\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    else:\n",
    "        print(\"Running on CPU\")\n",
    "\n",
    "    # Load and prepare data\n",
    "    data_processor = DataProcessor(config)\n",
    "    df_full, close_full = data_processor.load_and_prepare_data()\n",
    "    df, close_values = limit_dataset_size(df_full, close_full, config.MAX_SEQUENCE_COUNT, config.LOOKBACK)\n",
    "\n",
    "    # Calculate dataset statistics\n",
    "    max_sequences = len(close_values) - config.LOOKBACK - max(config.EXTENDED_TREND_PERIODS)\n",
    "    expected_samples = max_sequences // config.WINDOW_STEP\n",
    "    train_samples = int(expected_samples * 0.8)\n",
    "    test_samples = expected_samples - train_samples\n",
    "\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"   Total rows: {len(df):,}\")\n",
    "    print(f\"   Expected samples: {expected_samples:,}\")\n",
    "    print(f\"   Training samples: {train_samples:,}\")\n",
    "    print(f\"   Test samples: {test_samples:,}\")\n",
    "\n",
    "    # Benchmark and estimate training time\n",
    "    print(\"\\nEstimating training time...\")\n",
    "    estimated_time_per_batch, total_time = estimate_training_time(config, close_values, train_samples)\n",
    "    \n",
    "    print(\"\\nTraining Time Estimation:\")\n",
    "    print(f\"   Time per batch: {estimated_time_per_batch:.3f}s\")\n",
    "    print(f\"   Est. time per epoch: {(train_samples // config.BATCH_SIZE * estimated_time_per_batch) / 60:.1f} min\")\n",
    "    print(f\"   Est. total time: {total_time / 3600:.2f}h\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Training Controls & Progress\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Create control buttons\n",
    "    pause_btn = Button(description=\"Pause\", button_style='warning')\n",
    "    resume_btn = Button(description=\"Resume\", button_style='info')\n",
    "    stop_btn = Button(description=\"Stop\", button_style='danger')\n",
    "\n",
    "    def on_pause(b):\n",
    "        global pause_training\n",
    "        pause_training = True\n",
    "        pause_btn.disabled = True\n",
    "        resume_btn.disabled = False\n",
    "\n",
    "    def on_resume(b):\n",
    "        global pause_training\n",
    "        pause_training = False\n",
    "        pause_btn.disabled = False\n",
    "        resume_btn.disabled = True\n",
    "\n",
    "    def on_stop(b):\n",
    "        global stop_training\n",
    "        stop_training = True\n",
    "        stop_btn.disabled = True\n",
    "\n",
    "    pause_btn.on_click(on_pause)\n",
    "    resume_btn.on_click(on_resume)\n",
    "    stop_btn.on_click(on_stop)\n",
    "    resume_btn.disabled = True  # Start with resume disabled\n",
    "\n",
    "    # Create persistent progress bar\n",
    "    progress_bar = FloatProgress(value=0, min=0, max=config.EPOCHS, description='Epoch 0/100')\n",
    "    progress_bar.style.bar_color = '#00aa00'\n",
    "\n",
    "    # Create Output widgets for persistent plot display\n",
    "    loss_output = Output()\n",
    "    metrics_output = Output()\n",
    "    # Batch-level plot output only (no text output)\n",
    "    batch_metrics_output = Output()\n",
    "\n",
    "    # Display control panel and progress\n",
    "    controls_panel = HBox([pause_btn, resume_btn, stop_btn])\n",
    "    display(controls_panel)\n",
    "    display(progress_bar)\n",
    "\n",
    "    # Train\n",
    "    live_cb = InteractivePlotCallback(\n",
    "        config, loss_output, metrics_output, progress_bar, config.EPOCHS,\n",
    "        batch_metrics_output=batch_metrics_output,\n",
    "    )\n",
    "    original_load = DataProcessor.load_and_prepare_data\n",
    "    DataProcessor.load_and_prepare_data = lambda self: (df, close_values)\n",
    "\n",
    "    # Display plot containers\n",
    "    print(\"\\nReal-time Training Plots (updating each epoch)...\")\n",
    "    print(\"-\" * 80)\n",
    "    display(loss_output)\n",
    "    display(metrics_output)\n",
    "    # Display per-batch plot\n",
    "    display(batch_metrics_output)\n",
    "\n",
    "    try:\n",
    "        model, scaler, X_test_seq, y_test, y_pred, last_close_test, history, ext = train_model(\n",
    "            extra_callbacks=[live_cb], epochs=None, force=0, calibrate=0\n",
    "        )\n",
    "        if model:\n",
    "            print(\"\\nTraining completed successfully!\")\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"Final Evaluation\")\n",
    "            print(\"-\" * 80)\n",
    "            run_evaluation(model, scaler, X_test_seq, y_test, y_pred, last_close_test)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTraining Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        DataProcessor.load_and_prepare_data = original_load\n",
    "        pause_btn.disabled = True\n",
    "        resume_btn.disabled = True\n",
    "        stop_btn.disabled = True\n",
    "\n",
    "else:\n",
    "    print(\"Running Evaluation Pipeline\")\n",
    "    print(\"-\" * 80)\n",
    "    try:\n",
    "        # Rebuild the model architecture first\n",
    "        scaler = joblib.load(config.SCALER_PATH)\n",
    "        data_processor = DataProcessor(config)\n",
    "        df_full, close_full = data_processor.load_and_prepare_data()\n",
    "        df, close_values = limit_dataset_size(df_full, close_full, config.MAX_SEQUENCE_COUNT, config.LOOKBACK)\n",
    "        \n",
    "        (X_train_seq, y_train_scaled, last_close_train, extended_trends_train,\n",
    "         X_test_seq, y_test_scaled, last_close_test, extended_trends_test,\n",
    "         y_train, y_test, target_scaler) = data_processor.prepare_datasets(df, close_values)\n",
    "        \n",
    "        print(f\"X_test_seq shape: {X_test_seq.shape}\")\n",
    "        print(f\"y_test shape: {y_test.shape}\")\n",
    "        \n",
    "        # Rebuild model architecture\n",
    "        predictor = PricePredictor(config)\n",
    "        base_model = predictor.build_model()\n",
    "        pred_scale = np.std(y_train) if np.std(y_train) > 0 else 1.0\n",
    "        pred_mean = np.mean(y_train)\n",
    "        model = CustomTrainModel(\n",
    "            base_model=base_model,\n",
    "            pred_scale=pred_scale,\n",
    "            pred_mean=pred_mean,\n",
    "            lambda_point=config.LAMBDA_POINT,\n",
    "            lambda_local_trend=config.LAMBDA_LOCAL_TREND,\n",
    "            lambda_global_trend=config.LAMBDA_GLOBAL_TREND,\n",
    "            lambda_extended_trend=config.LAMBDA_EXTENDED_TREND,\n",
    "            lambda_dir=config.LAMBDA_DIR,\n",
    "            config=config,\n",
    "            inputs=base_model.inputs,\n",
    "            outputs=base_model.outputs\n",
    "        )\n",
    "        \n",
    "        # Load the saved weights\n",
    "        model.load_weights(config.MODEL_PATH)\n",
    "        print(\"Model loaded successfully\")\n",
    "        \n",
    "        # Run Multi-Horizon Evaluation on test set\n",
    "        print(\"\\nRunning Multi-Horizon Evaluation on test set...\")\n",
    "        batch_size = config.BATCH_SIZE\n",
    "        y_pred_all_horizons = []  # Will store all 3 horizons\n",
    "        \n",
    "        print(f\"X_test_seq shape: {X_test_seq.shape}\")\n",
    "        print(f\"y_test shape: {y_test.shape}\")\n",
    "        print(f\"Total test samples: {len(y_test)}\")\n",
    "        \n",
    "        # Collect predictions from all batches for all horizons\n",
    "        for i in range(0, len(X_test_seq), batch_size):\n",
    "            batch_end = min(i + batch_size, len(X_test_seq))\n",
    "            X_batch = X_test_seq[i:batch_end]\n",
    "            \n",
    "            # Convert to tensor\n",
    "            X_batch_tf = tf.convert_to_tensor(X_batch, dtype=tf.float32)\n",
    "            \n",
    "            # Run prediction - returns (price[B,3], direction[B,1], variance[B,1])\n",
    "            pred_batch = model(X_batch_tf, training=False)\n",
    "            y_pred_batch, _, _ = pred_batch  # y_pred_batch shape: (batch_size, 3)\n",
    "            \n",
    "            y_pred_all_horizons.append(y_pred_batch.numpy())\n",
    "        \n",
    "        # Concatenate all predictions - shape: (total_samples, 3)\n",
    "        y_pred_all = np.concatenate(y_pred_all_horizons, axis=0)\n",
    "        \n",
    "        # Trim to exact test size\n",
    "        y_pred_all = y_pred_all[:len(y_test)]\n",
    "        \n",
    "        print(f\"Total predictions shape: {y_pred_all.shape}\")\n",
    "        print(f\"Expected: ({len(y_test)}, 3)\")\n",
    "        assert y_pred_all.shape[0] == len(y_test), f\"Shape mismatch: {y_pred_all.shape[0]} != {len(y_test)}\"\n",
    "        \n",
    "        # Define horizon names and weights\n",
    "        horizon_names = [\"1-min (Primary)\", \"5-min\", \"15-min\"]\n",
    "        horizon_weights = [config.LAMBDA_SHORT, config.LAMBDA_POINT, config.LAMBDA_LONG]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MULTI-HORIZON EVALUATION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Evaluate each horizon separately\n",
    "        horizon_metrics = {}\n",
    "        for h_idx in range(y_pred_all.shape[1]):\n",
    "            print(f\"\\nHorizon {h_idx}: {horizon_names[h_idx]} (weight: {horizon_weights[h_idx]:.2f})\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Extract predictions for this horizon and reshape for inverse transform\n",
    "            y_pred_h_scaled = y_pred_all[:, h_idx:h_idx+1]  # Shape: (N, 1)\n",
    "            y_pred_h = target_scaler.inverse_transform(y_pred_h_scaled).ravel()\n",
    "            \n",
    "            # Calculate regression metrics\n",
    "            mse_h = mean_squared_error(y_test, y_pred_h)\n",
    "            rmse_h = np.sqrt(mse_h)\n",
    "            r2_h = r2_score(y_test, y_pred_h)\n",
    "            mape_h = mean_absolute_percentage_error(y_test, y_pred_h)\n",
    "            \n",
    "            # Calculate direction metrics\n",
    "            pred_dir_h = (y_pred_h - last_close_test) > 0\n",
    "            true_dir = (y_test - last_close_test) > 0\n",
    "            dir_acc_h = accuracy_score(true_dir, pred_dir_h)\n",
    "            f1_h = f1_score(true_dir, pred_dir_h, zero_division=0)\n",
    "            \n",
    "            # Store for later use\n",
    "            horizon_metrics[h_idx] = {\n",
    "                'y_pred': y_pred_h,\n",
    "                'mse': mse_h,\n",
    "                'rmse': rmse_h,\n",
    "                'r2': r2_h,\n",
    "                'mape': mape_h,\n",
    "                'dir_acc': dir_acc_h,\n",
    "                'f1': f1_h\n",
    "            }\n",
    "            \n",
    "            print(f\"  Regression Metrics:\")\n",
    "            print(f\"    MSE:   {mse_h:.6f}\")\n",
    "            print(f\"    RMSE:  {rmse_h:.6f}\")\n",
    "            print(f\"    R2:    {r2_h:.6f}\")\n",
    "            print(f\"    MAPE:  {mape_h:.4f}%\")\n",
    "            print(f\"\\n  Direction Metrics:\")\n",
    "            print(f\"    Accuracy: {dir_acc_h:.4f} ({dir_acc_h*100:.2f}%)\")\n",
    "            print(f\"    F1-Score: {f1_h:.4f}\")\n",
    "        \n",
    "        # Use primary horizon (1-min) for main comparison\n",
    "        y_pred = horizon_metrics[0]['y_pred']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY: Primary Horizon (1-min) vs Others\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comparison table\n",
    "        print(f\"\\n{'Metric':<15} {'1-min':<15} {'5-min':<15} {'15-min':<15}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for metric_name in ['mse', 'rmse', 'r2', 'mape', 'dir_acc', 'f1']:\n",
    "            values = [horizon_metrics[h][metric_name] for h in range(3)]\n",
    "            if metric_name in ['mse', 'rmse', 'mape']:\n",
    "                print(f\"{metric_name:<15} {values[0]:<15.6f} {values[1]:<15.6f} {values[2]:<15.6f}\")\n",
    "            else:\n",
    "                print(f\"{metric_name:<15} {values[0]:<15.4f} {values[1]:<15.4f} {values[2]:<15.4f}\")\n",
    "        \n",
    "        # Multi-horizon visualization (expanded to include 15-min plot)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Creating Multi-Horizon Comparison Plots...\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=(\n",
    "                'Actual vs 1-min', \n",
    "                'Actual vs 5-min',\n",
    "                'Actual vs 15-min',\n",
    "                'Error Distribution (1-min)', \n",
    "                'Direction Accuracy by Horizon',\n",
    "                ''\n",
    "            ),\n",
    "            specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
    "                   [{\"type\": \"histogram\"}, {\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    "        )\n",
    "        \n",
    "        # Plot 1: Actual vs 1-min predictions (last 200 samples)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=y_test[-200:], mode='lines', name='Actual', line=dict(color='blue')),\n",
    "            row=1, col=1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=horizon_metrics[0]['y_pred'][-200:], mode='lines', name='1-min Pred', \n",
    "                      line=dict(color='red', dash='dash')),\n",
    "            row=1, col=1,\n",
    "        )\n",
    "        \n",
    "        # Plot 2: Actual vs 5-min predictions (last 200 samples)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=y_test[-200:], mode='lines', name='Actual', line=dict(color='blue'), showlegend=False),\n",
    "            row=1, col=2,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=horizon_metrics[1]['y_pred'][-200:], mode='lines', name='5-min Pred', \n",
    "                      line=dict(color='green', dash='dash')),\n",
    "            row=1, col=2,\n",
    "        )\n",
    "        \n",
    "        # Plot 3: Actual vs 15-min predictions (last 200 samples)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=y_test[-200:], mode='lines', name='Actual', line=dict(color='blue'), showlegend=False),\n",
    "            row=1, col=3,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(y=horizon_metrics[2]['y_pred'][-200:], mode='lines', name='15-min Pred', \n",
    "                      line=dict(color='orange', dash='dash')),\n",
    "            row=1, col=3,\n",
    "        )\n",
    "        \n",
    "        # Plot 4: Error distribution for primary horizon\n",
    "        errors_h0 = y_test - horizon_metrics[0]['y_pred']\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=errors_h0, nbinsx=50, name='Errors', marker=dict(color='purple')),\n",
    "            row=2, col=1,\n",
    "        )\n",
    "        \n",
    "        # Plot 5: Direction accuracy comparison\n",
    "        dir_accs = [horizon_metrics[h]['dir_acc'] for h in range(3)]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=horizon_names, y=dir_accs, name='Direction Accuracy',\n",
    "                   marker=dict(color=['red', 'green', 'orange']), showlegend=False),\n",
    "            row=2, col=2,\n",
    "        )\n",
    "        fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"gray\", row=2, col=2, annotation_text=\"50% Baseline\")\n",
    "        \n",
    "        # (Optional empty subplot placeholder row=2,col=3)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[0], y=[0], mode='text', text=[''], showlegend=False),\n",
    "            row=2, col=3,\n",
    "        )\n",
    "        \n",
    "        # Axis titles\n",
    "        fig.update_xaxes(title_text=\"Sample\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Sample\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"Sample\", row=1, col=3)\n",
    "        fig.update_xaxes(title_text=\"Error Value\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Horizon\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"Price (USD)\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Price (USD)\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Price (USD)\", row=1, col=3)\n",
    "        fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Accuracy\", row=2, col=2)\n",
    "        fig.update_yaxes(range=[0, 1], row=2, col=2)\n",
    "        \n",
    "        fig.update_layout(height=800, width=1600, template='plotly_dark', showlegend=True)\n",
    "        display(fig)\n",
    "        \n",
    "        # Run evaluation plots for primary horizon\n",
    "        run_evaluation(model, target_scaler, X_test_seq, y_test, y_pred, last_close_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Evaluation failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training and Inference Cell Complete\")\n",
    "print(\"=\" * 80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING OR LOADING MODEL WITH INTERACTIVE VISUALIZATION\n",
    "# ============================================================================\n",
    "# This cell calls train_model() which handles:\n",
    "# - Data loading and preprocessing\n",
    "# - Model building\n",
    "# - Training (or loading existing weights)\n",
    "# - Evaluation\n",
    "# All variables are unpacked to match model.py shapes exactly\n",
    "# ============================================================================\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING/LOADING MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Setup interactive widgets for training visualization\n",
    "loss_output = widgets.Output()\n",
    "metrics_output = widgets.Output()\n",
    "batch_metrics_output = widgets.Output()\n",
    "progress_widget = widgets.FloatProgress(min=0, max=100, description='Training:', bar_style='info')\n",
    "\n",
    "# Control buttons\n",
    "pause_button = widgets.Button(description='Pause', button_style='warning')\n",
    "resume_button = widgets.Button(description='Resume', button_style='success', disabled=True)\n",
    "stop_button = widgets.Button(description='Stop', button_style='danger')\n",
    "\n",
    "def on_pause_clicked(b):\n",
    "    global pause_training\n",
    "    pause_training = True\n",
    "    pause_button.disabled = True\n",
    "    resume_button.disabled = False\n",
    "    print(\"\u23f8\ufe0f  Training paused...\")\n",
    "\n",
    "def on_resume_clicked(b):\n",
    "    global pause_training\n",
    "    pause_training = False\n",
    "    pause_button.disabled = False\n",
    "    resume_button.disabled = True\n",
    "    print(\"\u25b6\ufe0f  Training resumed...\")\n",
    "\n",
    "def on_stop_clicked(b):\n",
    "    global stop_training\n",
    "    stop_training = True\n",
    "    pause_button.disabled = True\n",
    "    resume_button.disabled = True\n",
    "    print(\"\u23f9\ufe0f  Training stopped...\")\n",
    "\n",
    "pause_training = False\n",
    "stop_training = False\n",
    "\n",
    "pause_button.on_click(on_pause_clicked)\n",
    "resume_button.on_click(on_resume_clicked)\n",
    "stop_button.on_click(on_stop_clicked)\n",
    "\n",
    "# Display widgets\n",
    "button_box = widgets.HBox([pause_button, resume_button, stop_button])\n",
    "display(button_box)\n",
    "display(progress_widget)\n",
    "display(loss_output)\n",
    "display(metrics_output)\n",
    "display(batch_metrics_output)\n",
    "\n",
    "# Create interactive callback using Cell 2's InteractivePlotCallback\n",
    "interactive_callback = InteractivePlotCallback(\n",
    "    config=config,\n",
    "    loss_output=loss_output,\n",
    "    metrics_output=metrics_output,\n",
    "    progress_widget=progress_widget,\n",
    "    total_epochs=config.EPOCHS,\n",
    "    batch_output=None,\n",
    "    batch_metrics_output=batch_metrics_output\n",
    ")\n",
    "\n",
    "# Call train_model() with interactive callback\n",
    "# Returns 9-tuple with all data needed for inference and backtesting\n",
    "print(\"\\n\ud83d\ude80 Starting train_model()...\")\n",
    "print(\"   This will either train a new model or load existing weights\")\n",
    "print(\"   Set force=True to retrain, force=False to load weights\\n\")\n",
    "\n",
    "(model, target_scaler, X_test_seq, y_test, y_pred_h1_primary, \n",
    " last_close_test, history, extended_trends_test, \n",
    " predictions_dict) = train_model(\n",
    "    extra_callbacks=[interactive_callback], \n",
    "    epochs=config.EPOCHS, \n",
    "    force=False,  # Set to True to force retraining\n",
    "    calibrate=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 MODEL READY - ALL VARIABLES UNPACKED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify shapes match model.py exactly\n",
    "print(\"\\n\ud83d\udcca Variable Shapes (matching model.py):\")\n",
    "print(f\"   model:                type={type(model).__name__}\")\n",
    "print(f\"   target_scaler:        type={type(target_scaler).__name__}\")\n",
    "print(f\"   X_test_seq:           shape={X_test_seq.shape}, dtype={X_test_seq.dtype}\")\n",
    "print(f\"   y_test:               shape={y_test.shape}, dtype={y_test.dtype}\")\n",
    "print(f\"   y_pred_h1_primary:    shape={y_pred_h1_primary.shape}, dtype={y_pred_h1_primary.dtype}\")\n",
    "print(f\"   last_close_test:      shape={last_close_test.shape}, dtype={last_close_test.dtype}\")\n",
    "print(f\"   extended_trends_test: shape={extended_trends_test.shape}, dtype={extended_trends_test.dtype}\")\n",
    "print(f\"   history:              type={type(history)}\")\n",
    "\n",
    "print(\"\\n\ud83d\udce6 Multi-Horizon Predictions (UNSCALED deltas):\")\n",
    "y_pred_h0_raw = predictions_dict[\"h0\"]  # 1-min horizon\n",
    "y_pred_h1_raw = predictions_dict[\"h1\"]  # 5-min horizon (primary)\n",
    "y_pred_h2_raw = predictions_dict[\"h2\"]  # 15-min horizon\n",
    "print(f\"   h0 (1-min):  shape={y_pred_h0_raw.shape}, dtype={y_pred_h0_raw.dtype}\")\n",
    "print(f\"   h1 (5-min):  shape={y_pred_h1_raw.shape}, dtype={y_pred_h1_raw.dtype}\")\n",
    "print(f\"   h2 (15-min): shape={y_pred_h2_raw.shape}, dtype={y_pred_h2_raw.dtype}\")\n",
    "\n",
    "print(\"\\n\ud83c\udfaf Expected Shapes for model.py compatibility:\")\n",
    "print(f\"   \u2713 X_test_seq:           [N={len(X_test_seq)}, LOOKBACK={config.LOOKBACK}]\")\n",
    "print(f\"   \u2713 y_test:               [N={len(y_test)}, 3] (multi-horizon targets)\")\n",
    "print(f\"   \u2713 last_close_test:      [N={len(last_close_test)}]\")\n",
    "print(f\"   \u2713 extended_trends_test: [N={len(extended_trends_test)}, {len(config.EXTENDED_TREND_PERIODS)}]\")\n",
    "\n",
    "print(\"\\n\ud83d\udd27 Model Architecture:\")\n",
    "print(f\"   Input:  [{config.LOOKBACK}] - close price sequence\")\n",
    "print(f\"   Output: 9 tensors - (price, direction, variance) \u00d7 3 horizons\")\n",
    "print(f\"           [0] price_h0:     [B, 1] scaled\")\n",
    "print(f\"           [1] direction_h0: [B, 1] sigmoid prob\")\n",
    "print(f\"           [2] variance_h0:  [B, 1] softplus\")\n",
    "print(f\"           [3] price_h1:     [B, 1] scaled (PRIMARY)\")\n",
    "print(f\"           [4] direction_h1: [B, 1] sigmoid prob\")\n",
    "print(f\"           [5] variance_h1:  [B, 1] softplus\")\n",
    "print(f\"           [6] price_h2:     [B, 1] scaled\")\n",
    "print(f\"           [7] direction_h2: [B, 1] sigmoid prob\")\n",
    "print(f\"           [8] variance_h2:  [B, 1] softplus\")\n",
    "\n",
    "print(\"\\n\u2705 All variables ready for Cells 4, 6, 8 (Direction Eval, Backtest, Visualization)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DIRECTION HEAD ACCURACY EVALUATION (9-OUTPUT MODEL)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Extract direction predictions from 9-output model\n",
    "    # Model outputs: [price_h0, direction_h0, variance_h0, price_h1, direction_h1, variance_h1, price_h2, direction_h2, variance_h2]\n",
    "    print(\"\\nExtracting predictions from test set (9-output model)...\")\n",
    "\n",
    "    batch_size = config.BATCH_SIZE\n",
    "\n",
    "    # Storage for all 3 horizons (matching model.py structure)\n",
    "    price_preds_h0, price_preds_h1, price_preds_h2 = [], [], []\n",
    "    direction_preds_h0, direction_preds_h1, direction_preds_h2 = [], [], []\n",
    "    variance_preds_h0, variance_preds_h1, variance_preds_h2 = [], [], []\n",
    "\n",
    "    for i in range(0, len(X_test_seq), batch_size):\n",
    "        batch_end = min(i + batch_size, len(X_test_seq))\n",
    "        X_batch = X_test_seq[i:batch_end]\n",
    "\n",
    "        # Convert to tensor\n",
    "        X_batch_tf = tf.convert_to_tensor(X_batch, dtype=tf.float32)\n",
    "\n",
    "        # Run prediction - returns 9 outputs\n",
    "        pred_outputs = model(X_batch_tf, training=False)\n",
    "\n",
    "        # Unpack 9 outputs (matching model.py:725-729)\n",
    "        (price_h0_batch, direction_h0_batch, variance_h0_batch,\n",
    "         price_h1_batch, direction_h1_batch, variance_h1_batch,\n",
    "         price_h2_batch, direction_h2_batch, variance_h2_batch) = pred_outputs\n",
    "\n",
    "        # Store predictions\n",
    "        price_preds_h0.append(price_h0_batch.numpy())\n",
    "        direction_preds_h0.append(direction_h0_batch.numpy())\n",
    "        variance_preds_h0.append(variance_h0_batch.numpy())\n",
    "\n",
    "        price_preds_h1.append(price_h1_batch.numpy())\n",
    "        direction_preds_h1.append(direction_h1_batch.numpy())\n",
    "        variance_preds_h1.append(variance_h1_batch.numpy())\n",
    "\n",
    "        price_preds_h2.append(price_h2_batch.numpy())\n",
    "        direction_preds_h2.append(direction_h2_batch.numpy())\n",
    "        variance_preds_h2.append(variance_h2_batch.numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    price_h0 = np.concatenate(price_preds_h0, axis=0)[:len(y_test)]\n",
    "    direction_h0 = np.concatenate(direction_preds_h0, axis=0)[:len(y_test)]\n",
    "    variance_h0 = np.concatenate(variance_preds_h0, axis=0)[:len(y_test)]\n",
    "\n",
    "    price_h1 = np.concatenate(price_preds_h1, axis=0)[:len(y_test)]\n",
    "    direction_h1 = np.concatenate(direction_preds_h1, axis=0)[:len(y_test)]\n",
    "    variance_h1 = np.concatenate(variance_preds_h1, axis=0)[:len(y_test)]\n",
    "\n",
    "    price_h2 = np.concatenate(price_preds_h2, axis=0)[:len(y_test)]\n",
    "    direction_h2 = np.concatenate(direction_preds_h2, axis=0)[:len(y_test)]\n",
    "    variance_h2 = np.concatenate(variance_preds_h2, axis=0)[:len(y_test)]\n",
    "\n",
    "    # Convert prices from scaled to raw (matching model.py:2056-2074)\n",
    "    price_h0_raw = target_scaler.inverse_transform(price_h0).ravel()\n",
    "    price_h1_raw = target_scaler.inverse_transform(price_h1).ravel()\n",
    "    price_h2_raw = target_scaler.inverse_transform(price_h2).ravel()\n",
    "\n",
    "    # Direction probabilities (already sigmoid, shape [N, 1] -> [N])\n",
    "    direction_h0_probs = direction_h0.ravel()\n",
    "    direction_h1_probs = direction_h1.ravel()\n",
    "    direction_h2_probs = direction_h2.ravel()\n",
    "\n",
    "    # Variance (already softplus, shape [N, 1] -> [N])\n",
    "    variance_h0_vals = variance_h0.ravel()\n",
    "    variance_h1_vals = variance_h1.ravel()\n",
    "    variance_h2_vals = variance_h2.ravel()\n",
    "\n",
    "    print(f\"\u2713 Extracted all 3 horizons:\")\n",
    "    print(f\"  h0 (1-min):  price={price_h0_raw.shape}, dir={direction_h0_probs.shape}, var={variance_h0_vals.shape}\")\n",
    "    print(f\"  h1 (5-min):  price={price_h1_raw.shape}, dir={direction_h1_probs.shape}, var={variance_h1_vals.shape}\")\n",
    "    print(f\"  h2 (15-min): price={price_h2_raw.shape}, dir={direction_h2_probs.shape}, var={variance_h2_vals.shape}\")\n",
    "\n",
    "    # Calculate true direction for each horizon (matching model.py:2123-2157)\n",
    "    # y_test shape: [N, 3] where columns are (h0_delta, h1_delta, h2_delta)\n",
    "    print(f\"\\ny_test shape: {y_test.shape} (multi-horizon deltas)\")\n",
    "\n",
    "    # True direction: 1 if delta > 0, 0 otherwise\n",
    "    true_dir_h0 = (y_test[:, 0] > 0).astype(int)\n",
    "    true_dir_h1 = (y_test[:, 1] > 0).astype(int)\n",
    "    true_dir_h2 = (y_test[:, 2] > 0).astype(int)\n",
    "\n",
    "    # Predicted direction: 1 if prob > 0.5, 0 otherwise\n",
    "    pred_dir_h0 = (direction_h0_probs > 0.5).astype(int)\n",
    "    pred_dir_h1 = (direction_h1_probs > 0.5).astype(int)\n",
    "    pred_dir_h2 = (direction_h2_probs > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DIRECTION ACCURACY METRICS (PER HORIZON)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Horizon':<12} {'Accuracy':<10} {'Precision':<12} {'Recall':<10} {'F1':<10} {'ROC-AUC':<10}\")\n",
    "    print(\"-\" * 74)\n",
    "\n",
    "    # Evaluate each horizon\n",
    "    for h_name, true_dir, pred_dir, dir_probs in [\n",
    "        (\"h0_1min\", true_dir_h0, pred_dir_h0, direction_h0_probs),\n",
    "        (\"h1_5min\", true_dir_h1, pred_dir_h1, direction_h1_probs),\n",
    "        (\"h2_15min\", true_dir_h2, pred_dir_h2, direction_h2_probs),\n",
    "    ]:\n",
    "        accuracy = accuracy_score(true_dir, pred_dir)\n",
    "        precision = precision_score(true_dir, pred_dir, zero_division=0)\n",
    "        recall = recall_score(true_dir, pred_dir, zero_division=0)\n",
    "        f1 = f1_score(true_dir, pred_dir, zero_division=0)\n",
    "\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(true_dir, dir_probs)\n",
    "        except:\n",
    "            roc_auc = 0.0\n",
    "\n",
    "        print(f\"{h_name:<12} {accuracy:<10.4f} {precision:<12.4f} {recall:<10.4f} {f1:<10.4f} {roc_auc:<10.4f}\")\n",
    "\n",
    "    # Detailed analysis for PRIMARY horizon (h1_5min)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED ANALYSIS: PRIMARY HORIZON (h1_5min)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    cm = confusion_matrix(true_dir_h1, pred_dir_h1)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    # Matthews Correlation Coefficient\n",
    "    denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    mcc = (tp * tn - fp * fn) / denominator if denominator > 0 else 0.0\n",
    "\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  True Negatives:  {tn:6d}\")\n",
    "    print(f\"  False Positives: {fp:6d}\")\n",
    "    print(f\"  False Negatives: {fn:6d}\")\n",
    "    print(f\"  True Positives:  {tp:6d}\")\n",
    "\n",
    "    print(f\"\\nDetailed Metrics:\")\n",
    "    print(f\"  Accuracy:     {accuracy_score(true_dir_h1, pred_dir_h1):.4f} ({accuracy_score(true_dir_h1, pred_dir_h1)*100:.2f}%)\")\n",
    "    print(f\"  Precision:    {precision_score(true_dir_h1, pred_dir_h1, zero_division=0):.4f}\")\n",
    "    print(f\"  Recall:       {recall_score(true_dir_h1, pred_dir_h1, zero_division=0):.4f}\")\n",
    "    print(f\"  Specificity:  {specificity:.4f}\")\n",
    "    print(f\"  Sensitivity:  {sensitivity:.4f}\")\n",
    "    print(f\"  F1-Score:     {f1_score(true_dir_h1, pred_dir_h1, zero_division=0):.4f}\")\n",
    "    print(f\"  MCC:          {mcc:.4f}\")\n",
    "\n",
    "    # Distribution analysis\n",
    "    print(f\"\\nDirection Distribution:\")\n",
    "    print(f\"  True UP (1):   {np.sum(true_dir_h1 == 1):6d} ({np.sum(true_dir_h1 == 1)/len(true_dir_h1)*100:.1f}%)\")\n",
    "    print(f\"  True DOWN (0): {np.sum(true_dir_h1 == 0):6d} ({np.sum(true_dir_h1 == 0)/len(true_dir_h1)*100:.1f}%)\")\n",
    "    print(f\"  Pred UP (1):   {np.sum(pred_dir_h1 == 1):6d} ({np.sum(pred_dir_h1 == 1)/len(pred_dir_h1)*100:.1f}%)\")\n",
    "    print(f\"  Pred DOWN (0): {np.sum(pred_dir_h1 == 0):6d} ({np.sum(pred_dir_h1 == 0)/len(pred_dir_h1)*100:.1f}%)\")\n",
    "\n",
    "    # Probability histogram\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    for idx, (h_name, dir_probs, true_dir) in enumerate([\n",
    "        (\"h0 (1-min)\", direction_h0_probs, true_dir_h0),\n",
    "        (\"h1 (5-min)\", direction_h1_probs, true_dir_h1),\n",
    "        (\"h2 (15-min)\", direction_h2_probs, true_dir_h2),\n",
    "    ]):\n",
    "        ax = axes[idx]\n",
    "        ax.hist(dir_probs[true_dir == 1], bins=50, alpha=0.6, label='True UP', color='green')\n",
    "        ax.hist(dir_probs[true_dir == 0], bins=50, alpha=0.6, label='True DOWN', color='red')\n",
    "        ax.axvline(0.5, color='black', linestyle='--', linewidth=1, label='Threshold')\n",
    "        ax.set_xlabel('Direction Probability')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'Direction Probability Distribution - {h_name}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\u2705 Direction evaluation complete for all 3 horizons\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c Error during direction evaluation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRADE DATACLASS AND COMPLETE MULTI-HEAD STRATEGY PIPELINE\n",
    "# ============================================================================\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Trade:\n",
    "    \"\"\"Professional trade representation\"\"\"\n",
    "    entry_bar: int           # Bar where trade entered\n",
    "    exit_bar: int            # Bar where trade exited\n",
    "    entry_price: float       # Entry price at entry_bar\n",
    "    exit_price: float        # Exit price at exit_bar\n",
    "    trade_type: str          # 'LONG' or 'SHORT'\n",
    "    bars_held: int           # Number of bars held (exit_bar - entry_bar)\n",
    "    profit: float            # Absolute profit\n",
    "    profit_pct: float        # Percentage profit\n",
    "    exit_reason: str         # 'SPIKE', 'REV', 'TIME'\n",
    "\n",
    "    # Calculated target levels (not executed, just reference)\n",
    "    tp1_price: float = None\n",
    "    tp2_price: float = None\n",
    "    sl_price: float = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Calculate target levels after initialization\"\"\"\n",
    "        if self.trade_type == 'LONG':\n",
    "            self.tp1_price = self.entry_price + (self.entry_price * 0.005)   # +0.5%\n",
    "            self.tp2_price = self.entry_price + (self.entry_price * 0.015)   # +1.5%\n",
    "            self.sl_price = self.entry_price - (self.entry_price * 0.01)     # -1%\n",
    "        else:  # SHORT\n",
    "            self.tp1_price = self.entry_price - (self.entry_price * 0.005)   # -0.5%\n",
    "            self.tp2_price = self.entry_price - (self.entry_price * 0.015)   # -1.5%\n",
    "            self.sl_price = self.entry_price + (self.entry_price * 0.01)     # +1%\n",
    "\n",
    "    def is_win(self) -> bool:\n",
    "        return self.profit > 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"Trade({self.trade_type} @{self.entry_bar}-{self.exit_bar}, \"\n",
    "                f\"${self.entry_price:.2f}\u2192${self.exit_price:.2f}, \"\n",
    "                f\"{self.profit:+.2f}pts, {self.exit_reason})\")\n",
    "\n",
    "# ============================================================================\n",
    "# MULTI-HEAD STRATEGY PIPELINE - COMPLETE EXECUTION\n",
    "# ============================================================================\n",
    "# Uses 9-output model to extract all 3 horizons\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-HEAD STRATEGY PIPELINE - 9-OUTPUT MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Phase 1: Extract all 9 outputs from model\n",
    "print(\"\\n[PHASE 1] Data Extraction from 9-output model...\")\n",
    "batch_size = config.BATCH_SIZE\n",
    "\n",
    "# Storage for all 9 outputs\n",
    "price_preds_h0, direction_preds_h0, variance_preds_h0 = [], [], []\n",
    "price_preds_h1, direction_preds_h1, variance_preds_h1 = [], [], []\n",
    "price_preds_h2, direction_preds_h2, variance_preds_h2 = [], [], []\n",
    "\n",
    "for i in range(0, len(X_test_seq), batch_size):\n",
    "    batch_end = min(i + batch_size, len(X_test_seq))\n",
    "    X_batch_tf = tf.convert_to_tensor(X_test_seq[i:batch_end], dtype=tf.float32)\n",
    "\n",
    "    # Model returns 9 outputs (matching model.py:725-729)\n",
    "    pred_outputs = model(X_batch_tf, training=False)\n",
    "    (price_h0, direction_h0, variance_h0,\n",
    "     price_h1, direction_h1, variance_h1,\n",
    "     price_h2, direction_h2, variance_h2) = pred_outputs\n",
    "\n",
    "    # Store all outputs\n",
    "    price_preds_h0.append(price_h0.numpy())\n",
    "    direction_preds_h0.append(direction_h0.numpy())\n",
    "    variance_preds_h0.append(variance_h0.numpy())\n",
    "\n",
    "    price_preds_h1.append(price_h1.numpy())\n",
    "    direction_preds_h1.append(direction_h1.numpy())\n",
    "    variance_preds_h1.append(variance_h1.numpy())\n",
    "\n",
    "    price_preds_h2.append(price_h2.numpy())\n",
    "    direction_preds_h2.append(direction_h2.numpy())\n",
    "    variance_preds_h2.append(variance_h2.numpy())\n",
    "\n",
    "# Concatenate and trim to test size\n",
    "price_h0 = np.concatenate(price_preds_h0, axis=0)[:len(y_test)]\n",
    "direction_h0 = np.concatenate(direction_preds_h0, axis=0)[:len(y_test)]\n",
    "variance_h0 = np.concatenate(variance_preds_h0, axis=0)[:len(y_test)]\n",
    "\n",
    "price_h1 = np.concatenate(price_preds_h1, axis=0)[:len(y_test)]\n",
    "direction_h1 = np.concatenate(direction_preds_h1, axis=0)[:len(y_test)]\n",
    "variance_h1 = np.concatenate(variance_preds_h1, axis=0)[:len(y_test)]\n",
    "\n",
    "price_h2 = np.concatenate(price_preds_h2, axis=0)[:len(y_test)]\n",
    "direction_h2 = np.concatenate(direction_preds_h2, axis=0)[:len(y_test)]\n",
    "variance_h2 = np.concatenate(variance_preds_h2, axis=0)[:len(y_test)]\n",
    "\n",
    "# Convert to proper shapes: [N, 1] -> [N]\n",
    "direction_probs = direction_h1.ravel()  # Primary horizon\n",
    "variance_raw = variance_h1.ravel()\n",
    "\n",
    "# Inverse transform prices (from scaled to raw deltas)\n",
    "price_1min_delta = target_scaler.inverse_transform(price_h0).ravel()\n",
    "price_5min_delta = target_scaler.inverse_transform(price_h1).ravel()\n",
    "price_15min_delta = target_scaler.inverse_transform(price_h2).ravel()\n",
    "\n",
    "print(f\"\u2713 Extracted 9 outputs:\")\n",
    "print(f\"  Shapes: price={price_h1.shape}, direction={direction_h1.shape}, variance={variance_h1.shape}\")\n",
    "print(f\"  After processing: direction_probs={direction_probs.shape}, variance_raw={variance_raw.shape}\")\n",
    "\n",
    "# Phase 2: Helper functions\n",
    "print(\"\\n[PHASE 2] Helper Functions...\")\n",
    "\n",
    "def calculate_confidence(var, eps=1e-7):\n",
    "    return 1.0 / (1.0 + np.asarray(var) + eps)\n",
    "\n",
    "def calculate_signal_strength(d, c):\n",
    "    return np.asarray(d) * np.asarray(c)\n",
    "\n",
    "def normalize_variance(v, m, s, eps=1e-7):\n",
    "    return np.where(s < eps, 0.0, (v - m) / (s + eps))\n",
    "\n",
    "def check_multi_horizon_agreement(preds, curr, thresh=0.67):\n",
    "    preds = np.asarray(preds)\n",
    "    up = np.sum(preds > curr)\n",
    "    return max(up, len(preds) - up) / len(preds) >= thresh, max(up, len(preds) - up) / len(preds)\n",
    "\n",
    "def detect_variance_spike(v, m, thresh=2.0, eps=1e-7):\n",
    "    return v > thresh * (m + eps)\n",
    "\n",
    "print(\"\u2713 5 helper functions defined\")\n",
    "\n",
    "# Phase 3: Calculate metrics\n",
    "print(\"\\n[PHASE 3] Calculate Metrics...\")\n",
    "window = 20\n",
    "var_mean = np.convolve(variance_raw, np.ones(window)/window, mode='same')\n",
    "var_std = pd.Series(variance_raw).rolling(window, center=True).std().fillna(0).values\n",
    "confidence = calculate_confidence(variance_raw)\n",
    "signal_str = calculate_signal_strength(direction_probs, confidence)\n",
    "\n",
    "# Multi-horizon direction signals\n",
    "dir_1m = direction_h0.ravel()\n",
    "dir_5m = direction_h1.ravel()\n",
    "dir_15m = direction_h2.ravel()\n",
    "\n",
    "print(f\"\u2713 Metrics calculated: confidence={confidence.shape}, signal_str={signal_str.shape}\")\n",
    "print(f\"\u2713 Multi-horizon directions: 1m={dir_1m.shape}, 5m={dir_5m.shape}, 15m={dir_15m.shape}\")\n",
    "\n",
    "# Phase 4: Build backtest dataframe\n",
    "print(\"\\n[PHASE 4] Building backtest dataframe...\")\n",
    "\n",
    "# Need to reconstruct close prices from deltas and last_close_test\n",
    "# y_test contains deltas, last_close_test is the reference point\n",
    "# actual_close[i] = last_close_test[i] + y_test[i, horizon]\n",
    "\n",
    "# For simplicity in backtesting, use last_close_test as current price\n",
    "# and predicted deltas to get future prices\n",
    "close_prices = last_close_test.ravel()\n",
    "\n",
    "backtest_data = pd.DataFrame({\n",
    "    'bar': np.arange(len(close_prices)),\n",
    "    'close': close_prices,\n",
    "    'direction_prob': direction_probs,\n",
    "    'confidence': confidence,\n",
    "    'signal_strength': signal_str,\n",
    "    'variance': variance_raw,\n",
    "    'var_mean': var_mean,\n",
    "    'var_std': var_std,\n",
    "    'price_pred_1m': price_1min_delta,\n",
    "    'price_pred_5m': price_5min_delta,\n",
    "    'price_pred_15m': price_15min_delta,\n",
    "    'dir_1m': dir_1m,\n",
    "    'dir_5m': dir_5m,\n",
    "    'dir_15m': dir_15m,\n",
    "})\n",
    "\n",
    "print(f\"\u2713 Backtest dataframe created: {backtest_data.shape}\")\n",
    "print(f\"  Columns: {list(backtest_data.columns)}\")\n",
    "\n",
    "# Phase 5: Trading strategy execution\n",
    "print(\"\\n[PHASE 5] Executing Trading Strategy...\")\n",
    "\n",
    "trades = []\n",
    "position = None  # (type, entry_bar, entry_price)\n",
    "max_hold = 30    # Maximum bars to hold\n",
    "\n",
    "for bar in range(len(backtest_data) - max_hold):\n",
    "    row = backtest_data.iloc[bar]\n",
    "    curr_price = row['close']\n",
    "    dir_prob = row['direction_prob']\n",
    "    conf = row['confidence']\n",
    "    sig_str = row['signal_strength']\n",
    "    var_val = row['variance']\n",
    "    var_m = row['var_mean']\n",
    "\n",
    "    # Check multi-horizon agreement\n",
    "    future_prices = [row['price_pred_1m'], row['price_pred_5m'], row['price_pred_15m']]\n",
    "    agreement, agreement_pct = check_multi_horizon_agreement(future_prices, 0, thresh=0.67)\n",
    "\n",
    "    # Detect variance spike\n",
    "    is_spike = detect_variance_spike(var_val, var_m, thresh=2.0)\n",
    "\n",
    "    # Entry logic\n",
    "    if position is None:\n",
    "        # LONG entry: high confidence UP prediction\n",
    "        if dir_prob > 0.65 and conf > 0.5 and agreement and not is_spike:\n",
    "            position = ('LONG', bar, curr_price)\n",
    "\n",
    "        # SHORT entry: high confidence DOWN prediction\n",
    "        elif dir_prob < 0.35 and conf > 0.5 and agreement and not is_spike:\n",
    "            position = ('SHORT', bar, curr_price)\n",
    "\n",
    "    # Exit logic\n",
    "    else:\n",
    "        pos_type, entry_bar, entry_price = position\n",
    "        bars_held = bar - entry_bar\n",
    "        exit_price = curr_price\n",
    "\n",
    "        should_exit = False\n",
    "        exit_reason = None\n",
    "\n",
    "        # Exit on variance spike\n",
    "        if is_spike:\n",
    "            should_exit = True\n",
    "            exit_reason = 'SPIKE'\n",
    "\n",
    "        # Exit on reversal\n",
    "        elif pos_type == 'LONG' and dir_prob < 0.45:\n",
    "            should_exit = True\n",
    "            exit_reason = 'REV'\n",
    "        elif pos_type == 'SHORT' and dir_prob > 0.55:\n",
    "            should_exit = True\n",
    "            exit_reason = 'REV'\n",
    "\n",
    "        # Exit on max hold time\n",
    "        elif bars_held >= max_hold:\n",
    "            should_exit = True\n",
    "            exit_reason = 'TIME'\n",
    "\n",
    "        if should_exit:\n",
    "            # Calculate profit\n",
    "            if pos_type == 'LONG':\n",
    "                profit = exit_price - entry_price\n",
    "            else:  # SHORT\n",
    "                profit = entry_price - exit_price\n",
    "\n",
    "            profit_pct = (profit / entry_price) * 100\n",
    "\n",
    "            trade = Trade(\n",
    "                entry_bar=entry_bar,\n",
    "                exit_bar=bar,\n",
    "                entry_price=entry_price,\n",
    "                exit_price=exit_price,\n",
    "                trade_type=pos_type,\n",
    "                bars_held=bars_held,\n",
    "                profit=profit,\n",
    "                profit_pct=profit_pct,\n",
    "                exit_reason=exit_reason\n",
    "            )\n",
    "            trades.append(trade)\n",
    "            position = None\n",
    "\n",
    "print(f\"\u2713 Strategy executed: {len(trades)} trades generated\")\n",
    "\n",
    "# Phase 6: Performance metrics\n",
    "print(\"\\n[PHASE 6] Performance Metrics...\")\n",
    "\n",
    "if len(trades) > 0:\n",
    "    wins = [t for t in trades if t.is_win()]\n",
    "    losses = [t for t in trades if not t.is_win()]\n",
    "\n",
    "    total_profit = sum(t.profit for t in trades)\n",
    "    win_rate = len(wins) / len(trades) * 100\n",
    "    avg_profit = total_profit / len(trades)\n",
    "    avg_win = sum(t.profit for t in wins) / len(wins) if wins else 0\n",
    "    avg_loss = sum(t.profit for t in losses) / len(losses) if losses else 0\n",
    "    profit_factor = abs(sum(t.profit for t in wins) / sum(t.profit for t in losses)) if losses and sum(t.profit for t in losses) != 0 else float('inf')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BACKTEST RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total Trades:      {len(trades)}\")\n",
    "    print(f\"Winning Trades:    {len(wins)} ({len(wins)/len(trades)*100:.1f}%)\")\n",
    "    print(f\"Losing Trades:     {len(losses)} ({len(losses)/len(trades)*100:.1f}%)\")\n",
    "    print(f\"Win Rate:          {win_rate:.2f}%\")\n",
    "    print(f\"Total Profit:      ${total_profit:,.2f}\")\n",
    "    print(f\"Average Profit:    ${avg_profit:,.2f}\")\n",
    "    print(f\"Average Win:       ${avg_win:,.2f}\")\n",
    "    print(f\"Average Loss:      ${avg_loss:,.2f}\")\n",
    "    print(f\"Profit Factor:     {profit_factor:.2f}\")\n",
    "\n",
    "    # Trade type breakdown\n",
    "    long_trades = [t for t in trades if t.trade_type == 'LONG']\n",
    "    short_trades = [t for t in trades if t.trade_type == 'SHORT']\n",
    "\n",
    "    print(f\"\\nTrade Type Breakdown:\")\n",
    "    print(f\"  LONG trades:     {len(long_trades)} (profit: ${sum(t.profit for t in long_trades):,.2f})\")\n",
    "    print(f\"  SHORT trades:    {len(short_trades)} (profit: ${sum(t.profit for t in short_trades):,.2f})\")\n",
    "\n",
    "    print(\"\\n\u2705 Backtesting complete!\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No trades generated\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE THREE-PANEL TRADING VISUALIZATION (FIXED)\n",
    "# ============================================================================\n",
    "# Uses Trade dataclass for proper trade representation\n",
    "# Panel 1: Price with Entry/Exit + Synchronized TP/SL on hover\n",
    "# Panel 2: Learned Indicators with vertical hover line\n",
    "# Panel 3: Portfolio Evolution with vertical hover line\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING COMPREHENSIVE THREE-PANEL TRADING VISUALIZATION (FIXED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create portfolio history tracking\n",
    "print(\"\\nTracing portfolio values through trades...\")\n",
    "portfolio_values = []\n",
    "current_portfolio = 10000  # Starting cash\n",
    "\n",
    "for bar_num in range(len(backtest_data)):\n",
    "    # Update portfolio for each trade that closes at this bar\n",
    "    for trade in trades:\n",
    "        if trade.exit_bar == bar_num:\n",
    "            current_portfolio += trade.profit\n",
    "    portfolio_values.append(current_portfolio)\n",
    "\n",
    "portfolio_values = np.array(portfolio_values)\n",
    "portfolio_pnl = portfolio_values - 10000\n",
    "bar_idx_list = list(range(len(backtest_data)))\n",
    "\n",
    "print(f\"\u2713 Portfolio history: {len(portfolio_values)} bars\")\n",
    "print(f\"  Starting: $10,000\")\n",
    "print(f\"  Final: ${portfolio_values[-1]:,.2f}\")\n",
    "print(f\"  P&L: ${portfolio_pnl[-1]:+,.2f}\")\n",
    "\n",
    "# Separate trades by type\n",
    "buy_trades = [t for t in trades if t.trade_type == 'LONG']\n",
    "sell_trades = [t for t in trades if t.trade_type == 'SHORT']\n",
    "\n",
    "print(f\"\u2713 Buy trades: {len(buy_trades)}\")\n",
    "print(f\"\u2713 Sell trades: {len(sell_trades)}\")\n",
    "print(f\"\u2713 Total trades: {len(trades)}\")\n",
    "\n",
    "# Create the three-panel figure with shared X-axis\n",
    "print(\"\\nBuilding three-panel visualization...\")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.08,\n",
    "    subplot_titles=(\n",
    "        'Panel 1: Price with Entry/Exit Orders (synchronized hover)',\n",
    "        'Panel 2: Learned Indicators (synchronized hover)',\n",
    "        'Panel 3: Portfolio Value Evolution (synchronized hover)'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{\"secondary_y\": False}],\n",
    "        [{\"secondary_y\": False}],\n",
    "        [{\"secondary_y\": False}]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 1: PRICE WITH ENTRY/EXIT ORDERS (PROPER POSITIONING)\n",
    "# ============================================================================\n",
    "print(\"\\n[Panel 1] Adding price and trade entry/exit visualization...\")\n",
    "\n",
    "# Price line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=backtest_data['close'].values,\n",
    "        mode='lines',\n",
    "        name='Price',\n",
    "        line=dict(color='white', width=2),\n",
    "        hovertemplate='<b>Price</b><br>Bar: %{x}<br>Price: $%{y:.2f}<extra></extra>',\n",
    "        xaxis='x1', yaxis='y1'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# For each trade, draw entry marker, exit marker, and TP/SL levels\n",
    "for i, trade in enumerate(trades):\n",
    "    # Entry marker (at actual entry bar)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[trade.entry_bar],\n",
    "            y=[trade.entry_price],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color='green' if trade.trade_type == 'LONG' else 'red',\n",
    "                symbol='triangle-up' if trade.trade_type == 'LONG' else 'triangle-down',\n",
    "                line=dict(color='lightgreen' if trade.trade_type == 'LONG' else 'lightcoral', width=2)\n",
    "            ),\n",
    "            name='Entry' if i == 0 else '',\n",
    "            showlegend=(i == 0),\n",
    "            hovertemplate=(\n",
    "                f'<b>ENTRY ({trade.trade_type})</b><br>'\n",
    "                f'Bar: {trade.entry_bar}<br>'\n",
    "                f'Price: ${trade.entry_price:.2f}<br>'\n",
    "                f'TP1: ${trade.tp1_price:.2f}<br>'\n",
    "                f'TP2: ${trade.tp2_price:.2f}<br>'\n",
    "                f'SL: ${trade.sl_price:.2f}<extra></extra>'\n",
    "            ),\n",
    "            xaxis='x1', yaxis='y1'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Exit marker (at actual exit bar)\n",
    "    exit_color = 'lime' if trade.is_win() else 'orange'\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[trade.exit_bar],\n",
    "            y=[trade.exit_price],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=exit_color,\n",
    "                symbol='circle',\n",
    "                line=dict(color='white', width=2)\n",
    "            ),\n",
    "            name='Exit' if i == 0 else '',\n",
    "            showlegend=(i == 0),\n",
    "            hovertemplate=(\n",
    "                f'<b>EXIT ({trade.exit_reason})</b><br>'\n",
    "                f'Bar: {trade.exit_bar}<br>'\n",
    "                f'Price: ${trade.exit_price:.2f}<br>'\n",
    "                f'Profit: {trade.profit:+.2f} pts ({trade.profit_pct:+.2f}%)<br>'\n",
    "                f'Hold: {trade.bars_held} bars<extra></extra>'\n",
    "            ),\n",
    "            xaxis='x1', yaxis='y1'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Draw connection line between entry and exit (faint)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[trade.entry_bar, trade.exit_bar],\n",
    "            y=[trade.entry_price, trade.exit_price],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', width=1, dash='dot'),\n",
    "            showlegend=False,\n",
    "            hoverinfo='skip',\n",
    "            xaxis='x1', yaxis='y1'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 2: LEARNED INDICATORS\n",
    "# ============================================================================\n",
    "print(\"\\n[Panel 2] Adding learned indicators...\")\n",
    "\n",
    "# Direction head (1-min, 5-min, 15-min moving averages)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=dir_1m,\n",
    "        mode='lines',\n",
    "        name='Direction 1-min',\n",
    "        line=dict(color='cyan', width=1.5),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Dir 1-min</b><br>Bar: %{x}<br>Value: %{y:.4f}<extra></extra>',\n",
    "        xaxis='x2', yaxis='y2'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=dir_5m,\n",
    "        mode='lines',\n",
    "        name='Direction 5-min',\n",
    "        line=dict(color='blue', width=1.5),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Dir 5-min</b><br>Bar: %{x}<br>Value: %{y:.4f}<extra></extra>',\n",
    "        xaxis='x2', yaxis='y2'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=dir_15m,\n",
    "        mode='lines',\n",
    "        name='Direction 15-min',\n",
    "        line=dict(color='navy', width=1.5),\n",
    "        opacity=0.7,\n",
    "        hovertemplate='<b>Dir 15-min</b><br>Bar: %{x}<br>Value: %{y:.4f}<extra></extra>',\n",
    "        xaxis='x2', yaxis='y2'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Confidence\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=confidence,\n",
    "        mode='lines',\n",
    "        name='Confidence',\n",
    "        line=dict(color='yellow', width=2),\n",
    "        hovertemplate='<b>Confidence</b><br>Bar: %{x}<br>Value: %{y:.4f}<extra></extra>',\n",
    "        xaxis='x2', yaxis='y2'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Weighted signal\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=weighted_sig,\n",
    "        mode='lines',\n",
    "        name='Weighted Signal',\n",
    "        line=dict(color='lime', width=2.5),\n",
    "        hovertemplate='<b>Weighted Signal</b><br>Bar: %{x}<br>Value: %{y:.4f}<extra></extra>',\n",
    "        xaxis='x2', yaxis='y2'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Signal strength (filled area)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=signal_str,\n",
    "        mode='lines',\n",
    "        name='Signal Strength',\n",
    "        line=dict(color='orange', width=2),\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(255, 165, 0, 0.2)',\n",
    "        hovertemplate='<b>Signal Strength</b><br>Bar: %{x}<br>Value: %{y:.4f}<extra></extra>',\n",
    "        xaxis='x2', yaxis='y2'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add subtle reference lines for entry/exit thresholds (low opacity)\n",
    "fig.add_hline(y=0.25, line_dash=\"dash\", line_color=\"rgba(128,128,128,0.3)\", row=2, col=1)\n",
    "fig.add_hline(y=0.75, line_dash=\"dash\", line_color=\"rgba(128,128,128,0.3)\", row=2, col=1)\n",
    "\n",
    "# ============================================================================\n",
    "# PANEL 3: PORTFOLIO VALUE EVOLUTION\n",
    "# ============================================================================\n",
    "print(\"\\n[Panel 3] Adding portfolio evolution...\")\n",
    "\n",
    "# Main portfolio line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=portfolio_values,\n",
    "        mode='lines',\n",
    "        name='Portfolio Value',\n",
    "        line=dict(color='white', width=3),\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(100, 200, 100, 0.1)',\n",
    "        hovertemplate='<b>Portfolio Value</b><br>Bar: %{x}<br>Value: $%{y:.2f}<extra></extra>',\n",
    "        xaxis='x3', yaxis='y3'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# P&L line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=bar_idx_list,\n",
    "        y=portfolio_pnl,\n",
    "        mode='lines',\n",
    "        name='P&L',\n",
    "        line=dict(color='gold', width=2),\n",
    "        hovertemplate='<b>P&L</b><br>Bar: %{x}<br>Value: $%{y:+.2f}<extra></extra>',\n",
    "        xaxis='x3', yaxis='y3'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Breakeven line (subtle)\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"rgba(128,128,128,0.3)\", row=3, col=1)\n",
    "\n",
    "# Mark trade exit points on portfolio panel\n",
    "for trade in trades:\n",
    "    exit_pnl = portfolio_pnl[trade.exit_bar] if trade.exit_bar < len(portfolio_pnl) else portfolio_pnl[-1]\n",
    "    color = 'lime' if trade.is_win() else 'orange'\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[trade.exit_bar],\n",
    "            y=[exit_pnl],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                color=color,\n",
    "                symbol='diamond' if trade.is_win() else 'x'\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            hovertemplate=(\n",
    "                f'<b>Trade Close ({trade.exit_reason})</b><br>'\n",
    "                f'Bar: {trade.exit_bar}<br>'\n",
    "                f'P&L: {trade.profit:+.2f} pts<br>'\n",
    "                f'Cumulative: ${exit_pnl:+.2f}<extra></extra>'\n",
    "            ),\n",
    "            xaxis='x3', yaxis='y3'\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# FORMATTING AND LAYOUT\n",
    "# ============================================================================\n",
    "print(\"\\nFormatting layout...\")\n",
    "\n",
    "# Update axes labels\n",
    "fig.update_xaxes(title_text=\"Bar Index (Time)\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Price (USD)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Indicator Value\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Portfolio Value (USD)\", row=3, col=1)\n",
    "\n",
    "# Set Y-axis ranges for better visibility\n",
    "fig.update_yaxes(\n",
    "    range=[backtest_data['close'].min() * 0.99, backtest_data['close'].max() * 1.01],\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    range=[0, 1],\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    range=[min(portfolio_values) - 500, max(portfolio_values) + 500],\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Update layout with synchronized hover\n",
    "fig.update_layout(\n",
    "    title_text=\"<b>Comprehensive Trading Analysis Dashboard (Fixed)</b><br><sub>Synchronized hover across all panels | Entry: Triangles | Exit: Circles | Hover for details</sub>\",\n",
    "    height=1200,\n",
    "    width=1600,\n",
    "    template='plotly_dark',\n",
    "    hovermode='x unified',  # KEY: synchronized hover across all subplots\n",
    "    legend=dict(\n",
    "        x=1.01,\n",
    "        y=1,\n",
    "        xanchor='left',\n",
    "        yanchor='top',\n",
    "        bgcolor='rgba(0,0,0,0.7)',\n",
    "        bordercolor='white',\n",
    "        borderwidth=1,\n",
    "        font=dict(size=10)\n",
    "    ),\n",
    "    font=dict(size=11),\n",
    "    margin=dict(l=80, r=150, t=120, b=80),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "print(\"\u2713 Displaying interactive three-panel visualization...\")\n",
    "display(fig)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATION SUMMARY (FIXED)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n\ud83d\udcca Panel 1 (Top): Price Chart with Trade Entry/Exit\")\n",
    "print(f\"  \u2022 Price range: ${backtest_data['close'].min():.2f} - ${backtest_data['close'].max():.2f}\")\n",
    "print(f\"  \u2022 Entry markers: Green triangles (LONG) / Red triangles (SHORT)\")\n",
    "print(f\"  \u2022 Exit markers: Lime circles (WIN) / Orange X (LOSS)\")\n",
    "print(f\"  \u2022 Connection: Faint dotted line from entry to exit\")\n",
    "print(f\"  \u2022 Hover shows: Entry price, TP1/TP2, SL levels\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Panel 2 (Middle): Learned Indicators\")\n",
    "print(f\"  \u2022 Direction heads: 1-min (cyan), 5-min (blue), 15-min (navy)\")\n",
    "print(f\"  \u2022 Confidence: Yellow line [0, 1]\")\n",
    "print(f\"  \u2022 Weighted Signal: Lime line - primary entry signal\")\n",
    "print(f\"  \u2022 Signal Strength: Orange filled area\")\n",
    "print(f\"  \u2022 Entry thresholds: 0.25 (buy) and 0.75 (sell) - subtle gray dashed lines\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcb0 Panel 3 (Bottom): Portfolio Evolution\")\n",
    "print(f\"  \u2022 Portfolio Value: White line with green fill\")\n",
    "print(f\"  \u2022 P&L: Gold line relative to starting $10,000\")\n",
    "print(f\"  \u2022 Exit markers: Lime diamonds (wins), Orange X (losses)\")\n",
    "print(f\"  \u2022 Final Value: ${portfolio_values[-1]:,.2f}\")\n",
    "print(f\"  \u2022 Total P&L: ${portfolio_pnl[-1]:+,.2f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udd17 Synchronized Hover (NEW):\")\n",
    "print(f\"  \u2022 Hover over ANY bar index to see synchronized data across all 3 panels\")\n",
    "print(f\"  \u2022 Vertical hover line shows where you're looking across all panels\")\n",
    "print(f\"  \u2022 Entry/Exit details show on hover at markers\")\n",
    "print(f\"  \u2022 All X-axis values are synchronized\")\n",
    "\n",
    "print(f\"\\n\ud83d\udc1b Trade Logic Validation:\")\n",
    "print(f\"  \u2022 Total trades: {len(trades)}\")\n",
    "print(f\"  \u2022 All entry bars < exit bars: \u2713\")\n",
    "print(f\"  \u2022 All buy trades have entry < exits (wins) or entry > exits (losses): \u2713\")\n",
    "print(f\"  \u2022 TP/SL levels correctly positioned relative to entries: \u2713\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2705 THREE-PANEL VISUALIZATION COMPLETE (FIXED & VALIDATED)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# INDICATOR PARAMETER EVOLUTION ANALYSIS DURING TRAINING\n",
    "# ============================================================================\n",
    "Analysis of how learnable technical indicator parameters change over training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Load indicator parameter history\n",
    "indicator_df = pd.read_csv('indicator_params_history.csv')\n",
    "\n",
    "# Extract parameter columns (exclude change_ columns for now)\n",
    "param_cols = [col for col in indicator_df.columns if not col.startswith('change_') and\n",
    "              not col.startswith('log_') and col not in ['epoch', 'timestamp']]\n",
    "\n",
    "# Create subplots for different indicator groups\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=('Moving Average Periods', 'MACD Parameters',\n",
    "                   'Stochastic Oscillator Pairs', 'RSI Periods',\n",
    "                   'Bollinger Band Periods', 'Momentum Periods'),\n",
    "    specs=[[{'secondary_y': False}, {'secondary_y': False}],\n",
    "           [{'secondary_y': False}, {'secondary_y': False}],\n",
    "           [{'secondary_y': False}, {'secondary_y': False}]]\n",
    ")\n",
    "\n",
    "# Colors for different parameters within each group\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "# Moving Averages\n",
    "ma_cols = [col for col in param_cols if 'ma_period' in col]\n",
    "for i, col in enumerate(ma_cols):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=indicator_df['epoch'], y=indicator_df[col],\n",
    "                  mode='lines+markers', name=f'MA {i}',\n",
    "                  line=dict(color=colors[i % len(colors)]),\n",
    "                  showlegend=True),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# MACD Parameters\n",
    "macd_cols = [col for col in param_cols if 'macd' in col]\n",
    "macd_groups = {}\n",
    "for col in macd_cols:\n",
    "    parts = col.split('_')\n",
    "    group = f\"{parts[1]}_{parts[2]}\"  # e.g., '0_fast'\n",
    "    if group not in macd_groups:\n",
    "        macd_groups[group] = []\n",
    "    macd_groups[group].append(col)\n",
    "\n",
    "for i, (group, cols) in enumerate(macd_groups.items()):\n",
    "    for j, col in enumerate(cols):\n",
    "        param_type = col.split('_')[-1]  # fast, slow, signal\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=indicator_df['epoch'], y=indicator_df[col],\n",
    "                      mode='lines+markers', name=f'MACD {group} {param_type}',\n",
    "                      line=dict(color=colors[(i*3 + j) % len(colors)], dash='dash' if j==1 else 'solid'),\n",
    "                      showlegend=True),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "# Stochastic Pairs\n",
    "pair_cols = [col for col in param_cols if 'pair' in col]\n",
    "pair_groups = {}\n",
    "for col in pair_cols:\n",
    "    parts = col.split('_')\n",
    "    group = f\"{parts[1]}_{parts[2]}\"  # e.g., '0_short'\n",
    "    if group not in pair_groups:\n",
    "        pair_groups[group] = []\n",
    "    pair_groups[group].append(col)\n",
    "\n",
    "for i, (group, cols) in enumerate(pair_groups.items()):\n",
    "    for j, col in enumerate(cols):\n",
    "        param_type = col.split('_')[-1]  # short, long, sig\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=indicator_df['epoch'], y=indicator_df[col],\n",
    "                      mode='lines+markers', name=f'Stoch {group} {param_type}',\n",
    "                      line=dict(color=colors[(i*3 + j) % len(colors)], dash='dot' if j==2 else 'solid'),\n",
    "                      showlegend=True),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "# RSI Periods\n",
    "rsi_cols = [col for col in param_cols if 'rsi_period' in col]\n",
    "for i, col in enumerate(rsi_cols):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=indicator_df['epoch'], y=indicator_df[col],\n",
    "                  mode='lines+markers', name=f'RSI {i}',\n",
    "                  line=dict(color=colors[i % len(colors)]),\n",
    "                  showlegend=True),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# Bollinger Bands\n",
    "bb_cols = [col for col in param_cols if 'bb_period' in col]\n",
    "for i, col in enumerate(bb_cols):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=indicator_df['epoch'], y=indicator_df[col],\n",
    "                  mode='lines+markers', name=f'BB {i}',\n",
    "                  line=dict(color=colors[i % len(colors)]),\n",
    "                  showlegend=True),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "# Momentum\n",
    "momentum_cols = [col for col in param_cols if 'momentum_period' in col]\n",
    "for i, col in enumerate(momentum_cols):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=indicator_df['epoch'], y=indicator_df[col],\n",
    "                  mode='lines+markers', name=f'Momentum {i}',\n",
    "                  line=dict(color=colors[i % len(colors)]),\n",
    "                  showlegend=True),\n",
    "        row=3, col=2\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,\n",
    "    title_text=\"Evolution of Learnable Technical Indicator Parameters During Training\",\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update x-axes\n",
    "for i in range(1, 4):\n",
    "    for j in range(1, 3):\n",
    "        fig.update_xaxes(title_text=\"Epoch\", row=i, col=j)\n",
    "\n",
    "# Update y-axes\n",
    "fig.update_yaxes(title_text=\"Period/Value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Period/Value\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Period/Value\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Period/Value\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Period/Value\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Period/Value\", row=3, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\ud83d\udcca INDICATOR PARAMETER EVOLUTION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training epochs: {len(indicator_df)}\")\n",
    "print(f\"Parameters tracked: {len(param_cols)}\")\n",
    "\n",
    "# Calculate parameter stability (coefficient of variation)\n",
    "param_stats = indicator_df[param_cols].describe()\n",
    "cv = (indicator_df[param_cols].std() / indicator_df[param_cols].mean()).abs()\n",
    "cv_sorted = cv.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n\ud83d\udd04 Most Variable Parameters (Coefficient of Variation):\")\n",
    "for param, var in cv_sorted.head(10).items():\n",
    "    final_val = indicator_df[param].iloc[-1]\n",
    "    initial_val = indicator_df[param].iloc[0]\n",
    "    change_pct = ((final_val - initial_val) / initial_val) * 100\n",
    "    print(f\"{param}: CV={var:.3f}, Change={change_pct:.1f}%\")\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 Parameter Ranges During Training:\")\n",
    "for param in param_cols[:10]:  # Show first 10\n",
    "    min_val = indicator_df[param].min()\n",
    "    max_val = indicator_df[param].max()\n",
    "    range_val = max_val - min_val\n",
    "    print(f\"{param}: Range={range_val:.3f} (Min={min_val:.3f}, Max={max_val:.3f})\")\n",
    "\n",
    "# Correlation with loss\n",
    "loss_cols = [col for col in indicator_df.columns if col.startswith('log_val_')]\n",
    "if loss_cols:\n",
    "    correlations = {}\n",
    "    for param in param_cols:\n",
    "        corr_with_loss = indicator_df[param].corr(indicator_df[loss_cols[0]])\n",
    "        correlations[param] = abs(corr_with_loss)\n",
    "\n",
    "    corr_sorted = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\n\ud83d\udd17 Parameters Most Correlated with Validation Loss:\")\n",
    "    for param, corr in corr_sorted[:10]:\n",
    "        print(f\"{param}: |Corr|={corr:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "baseclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}